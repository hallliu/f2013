\documentclass{article}
\usepackage{geometry}
\usepackage[namelimits,sumlimits]{amsmath}
\usepackage{amssymb,amsfonts}
\usepackage{multicol}
\usepackage{mathrsfs}
\usepackage[cm]{fullpage}
\newcommand{\nc}{\newcommand}
\newcommand{\tab}{\hspace*{5em}}
\newcommand{\conj}{\overline}
\newcommand{\dd}{\partial}
\nc{\cn}{\mathbb{C}}
\nc{\rn}{\mathbb{R}}
\nc{\qn}{\mathbb{Q}}
\nc{\zn}{\mathbb{Z}}
\nc{\aff}{\mathbb{A}}
\nc{\proj}{\mathbb{P}}
\nc{\pd}[2]{\frac{\partial {#1}}{\partial {#2}}}
\nc{\ep}{\epsilon}
\nc{\topo}{\mathscr{T}}
\nc{\basis}{\mathscr{B}}
\nc{\nullset}{\varnothing}
\nc{\openm}{\begin{pmatrix}}
\nc{\closem}{\end{pmatrix}}
\begin{document}
Name: Hall Liu

Date: \today 
\vspace{1.5cm}
\subsection*{2}
We have $H$ is a subspace of $V$ because each $\rho(h)$ is a linear map preserving sums and scalar products. To show that it is $\rho-$invariant, consider an arbitrary $g\in G$ and $w\in V^H$. Since $H$ is normal, we have $g^{-1}hg\in H$, so $(g^{-1}hg)\cdot w=w$ for all $h\in H$. By acting with $g$ on both sides, we obtain $h\cdot(g\cdot w)=g\cdot w$, implying that $g\cdot w\in V^H$. This sub-representation does not need to be trivial: consider $A_5\triangleleft S_5$ acting on $\cn^5$ with the permutation representation. The $A_5-$invariants are the subspace spanned by $(1,1,1,1,1)$.
\subsection*{3}
By defn, $T$ is a $G$-linear map if for all $g\in G$ and $v\in V$ we have $T(\rho_1(g)v)=\rho_2(g)T(v)$. Let $w=(v,T(v))\in W$, and consider the action of $g$ on $w$ via $\rho_1\oplus\rho_2$. This results in $(\rho_1(g)v,\rho_2(g)T(v))=(\rho_1(g)v,T(\rho_1(g)v))\in W$, so $W$ is a sub-representation of $\rho_1\oplus\rho_2$. Conversely, if we have $g\cdot w=(\rho_1(g)v,\rho_2(g)T(v))=(v', T(v'))\in W$, we'd have $\rho_1(g)v=v'\implies \rho_2(g)T(v)=T(\rho_1(g)v)$ for all $v,g$, implying that $T$ is a $G$-linear map.
\subsection*{4}
a. Suppose $V$ is not itself irreducible. Then it contains sub-representations. Take the minimum of the degrees of these subrepresentations. Then any subrepresentation with this minimal degree must be irreducible. If it weren't, it would contain a proper subspace which is also a subspace of $V$ invariant under the action of $G$, which would violate the minimality.

\noindent b. impossible? consider some $v$ in the irreducible subrep. its orbit is contained in the subrep and is therefore equal to the subreq. 
\subsection*{5}
a. If there is a common eigenvector, then the subspace spanned by that eigenvector is a subrepresentation, so the representation is reducible. Conversely, if the representation is reducible, then it must have a subrepresentation of degree $1$ and of degree $2$, since taking the orthogonal complement yields another subrepresentation. Then, any vector lying on the subrepresentation of degree $1$ must be a common eigenvector. 

\noindent b. Consider the direct sum of two copies of the standard representation of $S_3$. This is of degree $4$ and is clearly reducible by construction. However, it can't have a common eigenvector, since if it did, it would imply that the matrices in one of the copies of the standard rep have a common eigenvector, which would imply that the standard representation is reducible since it's only two-dimensional.
\subsection*{6}
a. Denote the diagonal matrix $\openm a&0&0\\0&b&0\\0&0&c\closem$ as $\{a,b,c\}$. Let $\psi(1)=\psi(-1)=\{1,1,1\}, \psi(i)=\{1,-1,-1\}, \psi(j)=\{-1,1,-1\}, \psi(k)=\{-1,-1,1\}$. This satisfies all the relations that the quaternion group does, so it's a homomorphism. 

\noindent b. The matrices all have $e_1$ as an eigenvector, so the $x$-axis is invariant under actions of the group, which makes it a subrep.

\noindent c. The kernel is just $\{1, -1\}$.
\subsection*{7}
a. From the book, the complement of the invariant subspace generated by $(1,1,1)$ is the set of points $(x,y,z)$ such that $x+y+z=0$. This space is spanned by the points $(1,-1,0)$ and $(0,1,-1)$. The action of elements of $S_3$ on this basis is to permute the coordinates, so $(1\ 2\ 3)$ would send $(1,-1,0)$ to $(0,1,-1)$ then to $(-1,0,1)$, and so on.

\noindent b. If $V$ were reducible, it would need to have a one-dimensional subspace invariant under the action of $S_3$. That is, a vector would need to exist with its coordinates summing to $0$ but changing only by a scalar factor under any permutation of coordinates. If we have $(a,b,c)\in V$, we'd need $(b,a,c)=\lambda(a,b,c)\implies\lambda=1\implies a=b$, and $(a,c,b)=\lambda'(a,b,c)\implies\lambda'=1\implies b=c$, which contradicts $a+b+c=0$ since they're not all zero.

\subsection*{8}
The matrices formed by the elements of $G$ are all of the form $\openm1&n\\0&1\closem$ where $n\in\zn$. We have that $\openm1\\0\closem$ is an eigenvector of all of these matrices with eigenvalue $1$, so the space spanned by $e_1$ is an invariant subspace. However, the characteristic polynomial of these matrices has a double root at $1$, and thus $e_1$ is the only nonzero eigenvector of the matrices from $G$. Therefore there can be no other invariant subspaces.

\subsection*{9}
a. Let $a_1=e_1\otimes e_1, a_2=e_1\otimes e_2$, and so on. We have $T'=T\otimes T:\rn^2\otimes\rn^2\to\rn^2\otimes\rn^2$, with $T\otimes T(e_i\otimes e_j)=T(e_i)\otimes T(e_j)$, so $T'(e_1\otimes e_1)=(3e_1+5e_2)\otimes(3e_1+5e_2)=9a_1+15a_2+15a_3+9a_4$, and so on. In matrix form with the order of the basis elements $a_1, a_2, a_3, a_4$, the matrix of $T'$ is 
$$\openm9&3&3&1\\15&6&5&2\\15&5&6&2\\9&10&10&4\closem$$

\noindent b. $\bigwedge^3 V$ is the zero vector space, so $T$ acts trivially.

\subsection*{10}
a. Let $\dim(V)=n, \dim(W)=m$. Let $\{w_1,\ldots,w_m\}$ be a basis for $W$ and $\{\phi_1,\ldots,\phi_n\}$ be a basis for $V$, where $\phi_i(v_j)=1$ if $i=j$ and $0$ otherwise. Then, we can write a basis of $W\otimes V^{*}$ as $\{w_i\otimes \phi_j, i\in[1,m], j\in[1,n]\}$. Associate $w_i\otimes\phi_j$ to the function that takes $v_j$ to $w_i$, and all other basis vectors of $V$ to $0$. It is clear that we can build up any linear map from $V$ to $W$ by adding together these maps: taking any linear map, we look at where it sends each basis vector of $V$ (a linear combination of the $w_i$, which can be obtained by making linear combinations of the tensored-together elements), and then just add the rest of them up. 

\noindent b. Use the definition of the action of $g$ upon an element $\phi$ of $\text{Hom}(V,W)$ as $(g\phi)(v)=g\phi(g^{-1}v)$. Let $\phi$ be a basis element of $\text{Hom}(V,W)$, sending $v_x$ to $w_y$. Let $g^{-1}$ have the matrix $(a_{ij})$ over $V$ and $g$ have the matrix $(b_{ij})$ over $W$. Then, $(g\phi)(v_i)=g\phi(\sum a_{ki}v_k)=a_{xi}gw_j=a_{xi}$


\end{document}
