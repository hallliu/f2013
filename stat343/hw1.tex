\documentclass{article}
\usepackage{geometry}
\usepackage[namelimits,sumlimits]{amsmath}
\usepackage{amssymb,amsfonts}
\usepackage{multicol}
\usepackage{graphicx}
\usepackage[cm]{fullpage}
\newcommand{\tab}{\hspace*{5em}}
\newcommand{\conj}{\overline}
\newcommand{\dd}{\partial}
\newcommand{\ep}{\epsilon}
\newcommand{\openm}{\begin{pmatrix}}
\newcommand{\closem}{\end{pmatrix}}
\DeclareMathOperator{\cov}{cov}
\DeclareMathOperator{\se}{se}
\newcommand{\nc}{\newcommand}
\newcommand{\rn}{\mathbb{R}}
\nc{\h}[1]{\widehat{#1}}
\nc{\ssn}[1]{\subsubsection*{#1}}
\begin{document}
Name: Hall Liu

Date: \today 
\vspace{1.5cm}

\subsection*{2.1}
\ssn{1}
<include picture here>

Based on this plot, a simple linear regression model may not be the best choice -- there are two plausible ways to view the trend. Either we can treat the two points at $(165.3,77.8)$ and $(169.6,71.2)$ as outliers and fit the rest of the data to a linear model, or we can decide that the two points that look like outliers are actually the result of random fluctuation and include them in the fit as well.
\ssn{2}
Let the $x$ vector denote the heights, the $y$ vector denote the weights. We have $\sum x_i=1655.2$ and there are $10$ data points, so we have $\conj{x}=165.52$. Similarly, $\sum y_i=594.7$ so $\conj{y}=59.47$. I'm not really sure how to show my work for computing the other stuff, so here's some R code to compute S** (where * stands for either X or Y).
\begin{verbatim}
sss <- function(v1,v2) {
     v1_avg <- mean(v1); v2_avg <- mean(v2)
     sum((v1-v1_avg)*(v2-v2_avg))
}
\end{verbatim}

and so we obtain $SXX=472.076,SYY=731.961$, and $SXY=274.786$.
The slope is $SXY/SXX=0.582$, and the intercept is $\conj{y}-m\conj{x}=-36.87$. 

<insert plotted line over graph>
\ssn{3}
We have $\widehat{\sigma^2}=\frac{RSS}{8}$. Once again, here is a function to compute the RSS:
\begin{verbatim}
rss <- function(x, y, slope, intercept) {
    sum((y-(intercept+slope*x))^2)
}
\end{verbatim}
will calculate the RSS. Running this, we get $RSS=572.014$ so $\widehat{\sigma^2}=71.5$.

The estimate for the variance of $\h{\beta_1}$ is $\h{\sigma^2}/SXX=71.5/472.076=0.1514$ and the estimate for variance of $\h{\beta_0}$ is $\h{\sigma}^2\left(1/n+\conj{x}^2/SXX\right)=4156.64$. Estimated covariance is $-\h{\sigma}^2\frac{\conj{x}}{SXX}=-25.06$.

The $t$-statistic for $\h{\beta_0}$ is $\frac{\h{\beta_0}}{\sigma_{\beta_0}}=-0.572$ and the $t$-statistic for $\h{\beta_1}$ has the same form with a value of $1.496$. Both these values are distributed according to $t_8$ under the null hypothesis. Using a two-sided test, the $p$-value for $\h{\beta_0}$ is $0.583$ and the $p$-value for $\h{beta_1}$ is $0.173$.

\ssn{4}
The df of the regression is $1$ and the df of the residuals is $n-2$. The sum of squares for the regression is $SS_\text{res}=SYY-\frac{(SXY)^2}{SXX}=572.014$, and $SS_\text{reg}=\frac{(SXY)^2}{SXX}=159.947$. The mean of squares for each of the two is the $SS$ divided by df. The $F$-statistic is $\frac{MS_\text{reg}}{MS_\text{res}}=2.24$. Under the $F_{1,8}$ distribution, this has a $p$-value of $0.173$.

\begin{tabular}{cccccc}
\hline
Source & SS & df & MS & F & p\\
\hline
Regression & 159.947 & 1 & 159.947 & 2.24 & 0.173\\
Residuals & 572.014 & 8 & 71.50 \\
Total & 731.961& 9\\
\end{tabular}

Square root of $2.24$ is indeed $1.496$.

\subsection*{2.4}

\end{document}
