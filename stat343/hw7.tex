\documentclass{article}
\usepackage{geometry}
\usepackage[namelimits,sumlimits]{amsmath}
\usepackage{amssymb,amsfonts}
\usepackage{multicol}
\usepackage{graphicx}
\usepackage{mathrsfs}
\usepackage[cm]{fullpage}
\newcommand{\tab}{\hspace*{5em}}
\newcommand{\conj}{\overline}
\newcommand{\dd}{\partial}
\newcommand{\ep}{\epsilon}
\newcommand{\openm}{\begin{pmatrix}}
\newcommand{\closem}{\end{pmatrix}}
\DeclareMathOperator{\cov}{cov}
\DeclareMathOperator{\var}{var}
\DeclareMathOperator{\rk}{rk}
\DeclareMathOperator{\im}{im}
\newcommand{\nc}{\newcommand}
\newcommand{\rn}{\mathbb{R}}
\nc{\h}[1]{\widehat{#1}}
\nc{\ssn}[1]{\subsubsection*{#1}}
\nc{\inner}[2]{\langle #1,#2\rangle}
\begin{document}
Name: Hall Liu

Date: \today 
\vspace{1.5cm}

\subsection*{6.3}
We fit the desired combination of variables by creating a new data set, \verb|sal1|, and assigning its \verb|dose| field to be the log of \verb|salmonella$dose + 1|. The results are as follows:
\begin{verbatim}
Call:
lm(formula = colonies ~ dose, data = sal1)

Residuals:
    Min      1Q  Median      3Q     Max 
-16.376  -6.882  -1.509   5.400  29.119 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)   
(Intercept)   19.823      5.064   3.915  0.00123 **
dose           2.396      1.128   2.125  0.04955 * 
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 10.84 on 16 degrees of freedom
Multiple R-squared:  0.2201,    Adjusted R-squared:  0.1713 
F-statistic: 4.514 on 1 and 16 DF,  p-value: 0.04955
\end{verbatim}
and the plot is

\includegraphics[width=0.6\textwidth]{hw7_files/6_3_plot1.png}

As seen from the low $R^2$ value and the poor appearance of the plot, it may be a good idea to check for lack of fit. If we do so by fitting a model with parameters for each level of dose with
\begin{verbatim}
> a_alt = lm(colonies ~ factor(dose), sal1)
> points(sal1$dose, fitted(a_alt), pch=18)
> anova(a, a_alt)
Analysis of Variance Table

Model 1: colonies ~ dose
Model 2: colonies ~ factor(dose)
  Res.Df    RSS Df Sum of Sq      F Pr(>F)
1     16 1881.1                           
2     12 1091.3  4    789.73 2.1709 0.1342
\end{verbatim}
Since the $p$-value is high enough, we should accept the null hypothesis that the fit is good. Instead, the low $R^2$ value can be attributed to the naturally high variance in the observations.
\subsection*{6.5}
Least squares:
\begin{verbatim}
> a = lm(stack.loss ~ ., data=stackloss)
> summary(a)

Call:
lm(formula = stack.loss ~ ., data = stackloss)

Residuals:
    Min      1Q  Median      3Q     Max 
-7.2377 -1.7117 -0.4551  2.3614  5.6978 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept) -39.9197    11.8960  -3.356  0.00375 ** 
Air.Flow      0.7156     0.1349   5.307  5.8e-05 ***
Water.Temp    1.2953     0.3680   3.520  0.00263 ** 
Acid.Conc.   -0.1521     0.1563  -0.973  0.34405    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 3.243 on 17 degrees of freedom
Multiple R-squared:  0.9136,    Adjusted R-squared:  0.8983 
F-statistic:  59.9 on 3 and 17 DF,  p-value: 3.016e-09
\end{verbatim}
LAD:
\begin{verbatim}
> b = rq(stack.loss ~ ., data=stackloss)
> summary(b)

Call: rq(formula = stack.loss ~ ., data = stackloss)

tau: [1] 0.5

Coefficients:
             coefficients lower bd  upper bd 
(Intercept) -39.68986    -41.61973 -29.67754
Air.Flow      0.83188      0.51278   1.14117
Water.Temp    0.57391      0.32182   1.41090
Acid.Conc.   -0.06087     -0.21348  -0.02891
\end{verbatim}
Huber's:
\begin{verbatim}
> c = rlm(stack.loss ~ ., data=stackloss)
> summary(c)

Call: rlm(formula = stack.loss ~ ., data = stackloss)
Residuals:
Min       1Q   Median       3Q      Max 
-8.91753 -1.73127  0.06187  1.54306  6.50163 

Coefficients:
               Value    Std. Error t value 
(Intercept) -41.0265   9.8073    -4.1832
Air.Flow      0.8294   0.1112     7.4597
Water.Temp    0.9261   0.3034     3.0524
Acid.Conc.   -0.1278   0.1289    -0.9922

Residual standard error: 2.441 on 17 degrees of freedom
\end{verbatim}
Trimmed least squares:
\begin{verbatim}
> d = ltsreg(stack.loss ~ ., data=stackloss, nsamp="exact")
> d
Call:
lqs.formula(formula = stack.loss ~ ., data = stackloss, nsamp = "exact", 
    method = "lts")

Coefficients:
(Intercept)     Air.Flow   Water.Temp   Acid.Conc.  
 -3.581e+01    7.500e-01    3.333e-01    3.489e-17  

Scale estimates 0.8482 0.8645 
\end{verbatim}
The water temperature coefficient is very high for the least-squares method compared to the LAD or the trimmed least squares model, and it's somewhere in the middle for Huber's method. This suggests that there are outliers that are affecting least squares but not the more robust models. We see a similary magnitude difference with acid concentration, which suggests that it would be good to take a look at that too. Acid concentration goes from being insignificant under least squares to significant under LAD. Let's take a look at the diagnostics.

First, take a look at the jackknife residuals. We see that case $21$ has a jackknife residual of $-3.33$, while the Bonferroni threshold is $3.60$. This is pretty close, and if we take a look at the plot of stack loss versus airflow, we have the following:

\includegraphics[width=0.6\textwidth]{hw7_files/6_5_airflow.png}

Case 21 looks like it's quite a bit below the line. Let's remove it and see what least squares gives back:
\begin{verbatim}
> a1=lm(stack.loss ~ ., data=stackloss1)
> summary(a1)

Call:
lm(formula = stack.loss ~ ., data = stackloss1)

Residuals:
    Min      1Q  Median      3Q     Max 
-3.0449 -2.0578  0.1025  1.0709  6.3017 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept) -43.7040     9.4916  -4.605 0.000293 ***
Air.Flow      0.8891     0.1188   7.481 1.31e-06 ***
Water.Temp    0.8166     0.3250   2.512 0.023088 *  
Acid.Conc.   -0.1071     0.1245  -0.860 0.402338    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 2.569 on 16 degrees of freedom
(1 observation deleted due to missingness)
Multiple R-squared:  0.9488,  Adjusted R-squared:  0.9392 
F-statistic: 98.82 on 3 and 16 DF,  p-value: 1.541e-10
\end{verbatim}
This produces something more in line with what we got back from the more robust models.
\subsection*{7.2}
First, examine the raw scatterplot below. It does not seem to be a linear trend, nor does it seem to be piecewise or polynomial. Thus, transforming the response is probably our best bet, and we do so with the Box-Cox method.

\includegraphics[width=0.6\textwidth]{hw7_files/7_2_raw.png}

Running Box-Cox on the data gives us the following plot 

\includegraphics[width=0.6\textwidth]{hw7_files/7_2_boxcox.png}

which suggests that we should try transforming. Using $\lambda=3$, we transform the response and get the following scatterplot:

\includegraphics[width=0.6\textwidth]{hw7_files/7_2_transformed.png}

This looks more reasonable, so we fit a least-squares model to it and receive the following output

\begin{verbatim}
Call:
lm(formula = tr_yield ~ nitro, data = tr_cornnit)

Residuals:
    Min      1Q  Median      3Q     Max 
-455013 -190004    1157  175247  605739 

Coefficients:
        Estimate Std. Error t value Pr(>|t|)    
(Intercept) 489620.0    62248.8   7.866 8.63e-10 ***
nitro         2425.9      450.5   5.385 3.03e-06 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 273900 on 42 degrees of freedom
Multiple R-squared:  0.4084,    Adjusted R-squared:  0.3943 
F-statistic: 28.99 on 1 and 42 DF,  p-value: 3.029e-06
\end{verbatim}

The $R^2$ value is a bit low, but the plot displays a lot of variability for the response to each value of the predictor, so let's run a goodness-of-fit test on it. Creating a 

% TODO: this makes no sense. lambda=8 makes for a good fit, but not otherwise.
\end{document}
